{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make dir:  ./data\\6ef01aef-c9e9-490b-b9d7-44fddcb09922\n",
      "make dir:  ./data\\19838416-d12e-4aa6-bcb6-a61e4855d83b\n",
      "make dir:  ./data\\c62dd337-3612-4a5d-a00f-3d472f60a4e8\n",
      "make dir:  ./data\\e8237f4e-faa9-4289-9324-8b27ce90e3c2\n",
      "make dir:  ./data\\835cabd1-d8cb-49e4-82e2-86422971a534\n",
      "make dir:  ./data\\5a5a70f2-1100-48f7-94e3-bf3ac7668baf\n",
      "make dir:  ./data\\05b9bb29-c393-4120-b41c-9ef497c67d7b\n",
      "make dir:  ./data\\bc28c4eb-6947-422c-b26f-7d98a3956786\n",
      "make dir:  ./data\\43c9728a-b4c1-410d-8482-89eed28afe23\n",
      "processed  1  ...\n",
      "make dir:  ./data\\5f48f779-46cb-460b-91de-2f752d8157b0\n",
      "processed  2  ...\n",
      "make dir:  ./data\\6e01e8c6-6d83-4164-a027-1a5d59c94b2b\n",
      "processed  3  ...\n",
      "make dir:  ./data\\d9e6d447-6821-4c0e-8797-bf6f4442f85f\n",
      "processed  4  ...\n",
      "make dir:  ./data\\e41774b2-8e1b-40bc-99df-60d05d2bc17b\n",
      "processed  5  ...\n",
      "make dir:  ./data\\ee26cb80-c00a-4153-881e-3ce98c634974\n",
      "processed  6  ...\n",
      "make dir:  ./data\\75b131a1-1a56-4ba2-827d-43ac6cd2c07c\n",
      "processed  7  ...\n",
      "make dir:  ./data\\195b5de9-9348-440d-abb6-12c78333d389\n",
      "processed  8  ...\n",
      "make dir:  ./data\\7896de9c-e306-40bd-9654-722d3a31dc19\n",
      "processed  9  ...\n",
      "make dir:  ./data\\86593447-395f-42c9-b135-5cd2d28063c6\n",
      "processed  10  ...\n",
      "make dir:  ./data\\f9646a2e-b6bb-4bc0-bb27-c66365c2b9fb\n",
      "processed  11  ...\n",
      "make dir:  ./data\\90ba5381-9a0c-49ce-8c06-d65dd63a0493\n",
      "processed  12  ...\n",
      "make dir:  ./data\\d75eb848-c3c3-4efa-a309-9dcc6e9e1f8e\n",
      "processed  13  ...\n",
      "make dir:  ./data\\fab76283-ecbb-4d7a-befa-990999977446\n",
      "processed  14  ...\n",
      "make dir:  ./data\\1c9bf4b2-19c8-42c7-a8e7-32d57723fbf9\n",
      "processed  15  ...\n",
      "make dir:  ./data\\30c84276-8eac-4c4b-85e6-5fcb5fde229f\n",
      "processed  16  ...\n",
      "make dir:  ./data\\3e15140f-b7bd-4ec7-aef8-d6b6d0ebb265\n",
      "processed  17  ...\n",
      "make dir:  ./data\\55e09449-c0dc-45a8-8e13-5d89957304eb\n",
      "processed  18  ...\n",
      "make dir:  ./data\\5dc4dffb-864e-4ca2-b79d-dc69c1c2294a\n",
      "processed  19  ...\n",
      "make dir:  ./data\\60e66264-e8a9-47d8-ba80-747d1e5a1d00\n",
      "processed  20  ...\n",
      "make dir:  ./data\\610bb034-b90b-45f5-9f67-5328ff71c602\n",
      "processed  21  ...\n",
      "make dir:  ./data\\c9500e0a-1530-4d00-8fe0-27ffd5a95f5d\n",
      "processed  22  ...\n",
      "make dir:  ./data\\14168244-ef55-4e71-b6c0-bad9cf6faa18\n",
      "processed  23  ...\n",
      "make dir:  ./data\\0d9ec603-2285-4187-8bcf-d8ed777170fd\n",
      "processed  24  ...\n",
      "make dir:  ./data\\2febd317-0322-4098-9c5b-e73b54e202ea\n",
      "processed  25  ...\n",
      "make dir:  ./data\\535c6a01-33dc-46c6-ad19-8fd9feb99a06\n",
      "processed  26  ...\n",
      "make dir:  ./data\\72914afe-78cc-405e-9144-386195524a4a\n",
      "processed  27  ...\n",
      "make dir:  ./data\\74dadc87-8709-4e7c-98bb-0bdf290ee6f2\n",
      "processed  28  ...\n",
      "make dir:  ./data\\ed49dda9-0627-4d79-9b6e-f8eb899fa734\n",
      "processed  29  ...\n",
      "make dir:  ./data\\c2630462-a4d0-4038-bfb9-a443a1fdddc7\n",
      "processed  30  ...\n",
      "make dir:  ./data\\c085816f-f966-42a7-9cc9-86d06194077b\n",
      "processed  31  ...\n",
      "make dir:  ./data\\457112ee-4d5e-4d4e-a379-e57723fa51b3\n",
      "processed  32  ...\n",
      "make dir:  ./data\\49951460-172e-4210-9bdb-b1690f23454c\n",
      "processed  33  ...\n",
      "make dir:  ./data\\af3abf53-6a19-4207-8fd9-98e1445fe14e\n",
      "processed  34  ...\n",
      "make dir:  ./data\\e62e96c1-eee5-4fcb-b4df-8d0d8de56ae7\n",
      "processed  35  ...\n",
      "make dir:  ./data\\deda4672-57df-4c13-885c-dca105105a3b\n",
      "processed  36  ...\n",
      "make dir:  ./data\\5bd6134b-2ac1-4d80-a084-0e713e0d9916\n",
      "processed  37  ...\n",
      "make dir:  ./data\\584a36bb-1687-4ba0-9620-32487e57b24d\n",
      "processed  38  ...\n",
      "make dir:  ./data\\2f86a29d-802e-494c-add1-1bafaaf61b06\n",
      "processed  39  ...\n",
      "make dir:  ./data\\58c9df79-5f21-49e0-b0f4-49144e8fbfc3\n",
      "processed  40  ...\n",
      "make dir:  ./data\\6fa427cc-8911-4550-a640-dc2b29a651f0\n",
      "processed  41  ...\n",
      "make dir:  ./data\\bcac14db-2aec-4753-8263-921676b63015\n",
      "processed  42  ...\n",
      "make dir:  ./data\\82a82ac8-1b32-4836-a0b4-30d8f0372aa5\n",
      "processed  43  ...\n",
      "make dir:  ./data\\f3cfa02d-ba07-4ead-b80e-72f6772cbae2\n",
      "processed  44  ...\n",
      "make dir:  ./data\\ffac9a82-4363-4fed-b068-3e1d0db0a255\n",
      "processed  45  ...\n",
      "make dir:  ./data\\70ead6fe-3298-4f7d-80e6-338632b6fc70\n",
      "processed  46  ...\n",
      "make dir:  ./data\\11cb4c61-623f-4cb6-b45a-686e5cf4a8a1\n",
      "processed  47  ...\n",
      "make dir:  ./data\\28a79c7b-bcd8-4e00-9b91-00609265af3b\n",
      "processed  48  ...\n",
      "make dir:  ./data\\56a9e2d0-d4ca-4eaa-af9d-857a85f2ed39\n",
      "processed  49  ...\n",
      "make dir:  ./data\\58d1f779-7d5a-48e4-8838-e023295366dc\n",
      "processed  50  ...\n",
      "make dir:  ./data\\c7ec5ce1-e3d5-4118-9e01-2499ae00277f\n",
      "processed  51  ...\n",
      "make dir:  ./data\\bee6472c-4524-485a-988c-3f8d0c27dbe2\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "from util_selenium import *\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import pprint\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "\n",
    "def download_file(url, dst_path):\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as web_file:\n",
    "            data = web_file.read()\n",
    "            with open(dst_path, mode='wb') as local_file:\n",
    "                local_file.write(data)\n",
    "    except urllib.error.URLError as e:\n",
    "        print(e)\n",
    "\n",
    "class KurashiruDetail:\n",
    "    def __init__(self, driver, page_list, page_num = 707, wait_time = 2):\n",
    "        self.account = 'koeruqin1998@gmail.com'\n",
    "        self.password = 'tengteng98'\n",
    "        self.base_url = 'https://www.kurashiru.com/video_categories/1?page='\n",
    "\n",
    "        self.page_num = page_num\n",
    "        self.url_list = []\n",
    "\n",
    "        self.driver = driver\n",
    "        self.wait_time = wait_time\n",
    "\n",
    "        self.mymail = 'koeruqin1998@gmail.com'\n",
    "        self.mypass = 'tengteng98'\n",
    "\n",
    "        self.pagelist = page_list\n",
    "\n",
    "        self.path_dataset = \"./data\"\n",
    "        self.saved_num = 0\n",
    "\n",
    "        self.login(self.mymail, self.mypass)\n",
    "\n",
    "    \n",
    "    def login(self, mymail, mypass):\n",
    "\n",
    "        mydriverget(self.driver, self.base_url + \"1\", self.wait_time)\n",
    "        login_but = self.driver.find_element_by_xpath('//*[@id=\"header_app\"]/div/div[3]/span/div[2]')\n",
    "        mydriverclick(login_but, self.driver, self.wait_time)\n",
    "\n",
    "        field_login = self.driver.find_element_by_xpath('//*[@id=\"sessions_new\"]/div/div[2]/div[1]/div/input')\n",
    "        field_pass = self.driver.find_element_by_xpath('//*[@id=\"sessions_new\"]/div/div[2]/div[2]/div/input')\n",
    "\n",
    "        field_login.send_keys(self.mymail)\n",
    "        field_pass.send_keys(self.mypass)\n",
    "\n",
    "        login2 = self.driver.find_element_by_xpath('//*[@id=\"sessions_new\"]/div/div[2]/button[1]/div')\n",
    "        mydriverclick(login2, self.driver, self.wait_time)\n",
    "    \n",
    "    def scrape_all_url(self):\n",
    "        self.url_list = []\n",
    "        for j in range(self.page_num):\n",
    "            print(j)\n",
    "\n",
    "            newurl = self.base_url + str(j)\n",
    "\n",
    "            mydriverget(self.driver, newurl, self.wait_time)\n",
    "\n",
    "            ellist = mytrygetel(self.driver.find_elements_by_xpath, '//*[@id=\"partial_spa\"]/div[1]/div/div/main/div[2]/div/li[*]/div/a')\n",
    "\n",
    "            newlist = []\n",
    "\n",
    "            for i in range(len(ellist)):\n",
    "                self.url_list.append(ellist[i].get_attribute('href'))\n",
    "                newlist.append(ellist[i].get_attribute('href'))\n",
    "            \n",
    "            with open(\"kurasiru_url1.txt\", \"a\") as f:\n",
    "                for url_ in newlist:\n",
    "                    f.write(url_ + '\\n')\n",
    "\n",
    "            print(\"added \", len(ellist), \" urls\")\n",
    "            if len(self.url_list) > 0:\n",
    "                print(self.url_list[-1]) \n",
    "\n",
    "        return self.url_list\n",
    "\n",
    "    def get_detail(self):\n",
    "        #for page in self.pagelist:\n",
    "        le=len(self.pagelist)\n",
    "        for i in range(le):\n",
    "            page=self.pagelist[le-1-i]\n",
    "            uuid = os.path.basename(page)\n",
    "\n",
    "            datapath = os.path.join(self.path_dataset, uuid)\n",
    "            \n",
    "            if os.path.exists(datapath):\n",
    "                continue\n",
    "            else:\n",
    "                if not os.path.exists(datapath):\n",
    "                    os.mkdir(datapath)\n",
    "                    print(\"make dir: \", datapath)\n",
    "\n",
    "                mydriverget(self.driver, page, self.wait_time)\n",
    "\n",
    "                #ページが存在しない可能性も\n",
    "                try:\n",
    "                    url_video = self.driver.find_element_by_xpath('//*[@id=\"videos_show\"]/div/main/article[1]/article/div[1]/div/video/source[2]').get_attribute('src')\n",
    "                except:\n",
    "                    os.rmdir(datapath)\n",
    "                    continue\n",
    "\n",
    "                with open(os.path.join(datapath, \"video_url.txt\"), \"w\") as f:\n",
    "                    f.write(url_video)\n",
    "                \n",
    "                url_thumb = self.driver.find_element_by_xpath('//*[@id=\"videos_show\"]/div/main/article[1]/article/div[1]/div/video').get_attribute('poster')\n",
    "\n",
    "                download_file(url_thumb, os.path.join(datapath, \"thumbnail.jpg\"))\n",
    "\n",
    "                str_title = self.driver.find_element_by_xpath('//*[@id=\"videos_show\"]/div/main/article[1]/article/div[2]/h1').get_attribute('innerHTML')\n",
    "\n",
    "                with open(os.path.join(datapath, \"title.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(str_title)\n",
    "\n",
    "                numeric = self.driver.find_elements_by_xpath('//*[@id=\"videos_show\"]/div/main/article[1]/article/div[3]/div[1]/div[*]/span[2]')\n",
    "\n",
    "                with open(os.path.join(datapath, \"numeric.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "                    for data in numeric:\n",
    "                        f.write(data.get_attribute('innerHTML') + \"\\n\")\n",
    "                \n",
    "                ingredients = self.driver.find_elements_by_xpath('//*[@id=\"videos_show\"]/div/main/article[1]/article/section[1]/ul/li[*]/span[1]')\n",
    "                \n",
    "                with open(os.path.join(datapath, \"ingredients.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                    for g in ingredients:\n",
    "                        f.write(g.get_attribute('innerHTML') + \"\\n\")\n",
    "\n",
    "                instructions = self.driver.find_elements_by_xpath('//*[@id=\"videos_show\"]/div/main/article[1]/article/section[2]/ol/li[*]/span[2]')\n",
    "                \n",
    "                with open(os.path.join(datapath, \"instructions.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                    for i in instructions:\n",
    "                        f.write(i.get_attribute('innerHTML') + \"\\n\")\n",
    "                \n",
    "                path_tsukurepo = os.path.join(datapath, \"tsukurepo\")\n",
    "                if not os.path.exists(path_tsukurepo):\n",
    "                    os.mkdir(path_tsukurepo)\n",
    "                #//*[@id=\"videos_show\"]/div/main/div/article[1]/div/div[1]/div/div[1]/div/img\n",
    "                tsukurepo = self.driver.find_elements_by_xpath('//*[@id=\"videos_show\"]/div/main/div/article[1]/div/div[1]/div[*]/div[1]/div/img')\n",
    "\n",
    "                for i in range(len(tsukurepo)):\n",
    "                    try:\n",
    "                        download_file(tsukurepo[i].get_attribute('src'), os.path.join(path_tsukurepo, \"img\" + str(i) + \".jpg\"))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                self.saved_num += 1\n",
    "                print(\"processed \", self.saved_num, \" ...\")\n",
    "\n",
    "def main():\n",
    "    with open(\"./kurasiru_url.txt\", \"r\") as f:\n",
    "        datalist = f.read().split()\n",
    "\n",
    "   \n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    kurasiru = KurashiruDetail(driver, datalist)\n",
    "    kurasiru.get_detail()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
