{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denjo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/denjo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train\n",
      "data/test\n",
      "<__main__.FoodDataset object at 0x7fdba8239048>\n",
      "<__main__.FoodDataset object at 0x7fdb163c37b8>\n",
      "torch.Size([4, 3, 224, 224])\n",
      "torch.Size([4, 329])\n",
      "data/train/cba9a7a6-d6a4-4114-89f6-fdc5ceccf3dd\n",
      "epoch :24 loss: 0.06635957211256027\n",
      "['sans-serif']\n",
      "['sans-serif']\n",
      "('data/test/095dca73-6012-4652-a3ae-ac8ba9ab7e68', 'data/test/46c5ffd7-c190-431e-9b1e-8d86d284dc41', 'data/test/ce305e5d-f92b-47b2-960c-677e4bfc2438', 'data/test/dccdfd51-40c9-43cb-97ff-935ccd98eff2')\n",
      "0\n",
      "['塩', 'お湯', 'チーズ', '水', '卵', 'トマト', 'マヨネーズ', '油', '鶏', 'たまねぎ', '酒', 'しょうゆ', '豚', '大葉', 'ニンニク', '酢', '砂糖', 'オリーブ', 'パセリ', 'ごはん', 'ごま', 'ケチャップ', '塩こしょう', '黒こしょう', 'スパゲティ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['塩', 'チーズ', '水', '卵', 'マヨネーズ', '油', 'たまねぎ', 'しょうゆ', 'ニンニク', 'オリーブ', 'パセリ', '牛', '黒こしょう']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['塩', 'チーズ', 'クリーム', '糖', '水', '卵', '油', 'ミント', '砂糖', '薄力粉', '牛']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['塩', 'クリーム', '糖', '水', '卵', '油', '薄力粉', 'パン', '牛', 'バター']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/test/5d6d97b3-4c6c-496a-9faa-57b32d9a3ef8', 'data/test/62e4989a-5f5f-45d5-8aae-931a33be259d', 'data/test/b3fc0ac6-f48b-4f28-a77f-a9cce4cb56be', 'data/test/df752ecf-0112-4b95-b1c0-1a81f1c886dd')\n",
      "1\n",
      "['塩', 'チーズ', 'クリーム', '糖', '水', '卵', 'マヨネーズ', '油', 'たまねぎ', 'パセリ', 'じゃがいも', '薄力粉', 'パン']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['塩', 'チーズ', 'クリーム', '糖', '水', '卵', '油', '薄力粉', '牛']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import PIL\n",
    "from skimage import io, transform\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "#from config import Config\n",
    "if __name__ == '__main__':\n",
    "    plt.ion()  \n",
    "    # Data augmentation and normalization for training\n",
    "    # Just normalization for validation\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    class FoodDataset(torch.utils.data.Dataset):\n",
    "       \"\"\" Dataset object used to access the pre-processed VoxCelebDataset \"\"\"\n",
    "       def __init__(self, root, extension='.jpg',shuffle=False, transform=None, shuffle_frames=False, subset_size=None,phase=True):\n",
    "           \"\"\"\n",
    "           Instantiates the Dataset.\n",
    "           :param root: Path to the folder where the pre-processed dataset is stored.\n",
    "           :param extension: File extension of the pre-processed video files.\n",
    "           :param shuffle: If True, the video files will be shuffled.\n",
    "           :param transform: Transformations to be done to all frames of the video files.\n",
    "           :param shuffle_frames: If True, each time a video is accessed, its frames will be shuffled.\n",
    "           \"\"\"\n",
    "           if (phase==True):\n",
    "               self.root=os.path.join(root,'train')\n",
    "           else:\n",
    "               self.root=os.path.join(root,'test')\n",
    "           print(self.root)\n",
    "           self.transform = transform\n",
    "           self.files = glob.glob(os.path.join(self.root, \"*\"))\n",
    "           if shuffle:\n",
    "               random.shuffle(self.files)\n",
    "           self.length = len(self.files)\n",
    "           with open(os.path.join(root, \"all_labels.json\"), \"r\", encoding=\"utf8\") as f:\n",
    "               self.all_labels = json.load(f)\n",
    "           with open(os.path.join(root, \"labels_count2.json\"), \"r\", encoding=\"utf8\") as f:\n",
    "               self.labels_count = json.load(f)\n",
    "           self.num_to_label = []\n",
    "           for a_key in self.labels_count.keys():\n",
    "               if self.labels_count[a_key] >= 3:\n",
    "                    self.num_to_label.append(a_key)\n",
    "           self.label_to_num = {}\n",
    "           for i in range(len(self.num_to_label)):\n",
    "               self.label_to_num[self.num_to_label[i]] = i\n",
    "           \n",
    "           self.label_len = len(self.num_to_label)\n",
    "       \n",
    "       def read_ingredients(self, file_name):\n",
    "           with open(file_name, \"r\", encoding=\"utf8\") as f:\n",
    "               new_labels = f.read().split('\\n')\n",
    "           real_labels = []\n",
    "           for label in new_labels:\n",
    "               label = re.sub('\\(.*?\\)', '', label)\n",
    "               label = label.replace(' ', '')\n",
    "               if label != \"\":\n",
    "                   real_labels.append(label)\n",
    "\n",
    "           np_labels = np.zeros(self.label_len)\n",
    "           for real_label in real_labels:\n",
    "               processed_label = self.all_labels[real_label]\n",
    "               #print(real_label)\n",
    "               #print(processed_label)\n",
    "               try:\n",
    "                    a_idx = self.label_to_num[processed_label]\n",
    "                    np_labels[a_idx] = 1\n",
    "               except:\n",
    "                    pass\n",
    "               \n",
    "               \n",
    "           return np_labels\n",
    "       def __len__(self):\n",
    "           return self.length\n",
    "       def __getitem__(self, idx):\n",
    "           item_path = self.files[idx]\n",
    "           uuid = item_path\n",
    "           img_path = os.path.join(item_path, \"thumbnail.jpg\")\n",
    "           ingredients_path = os.path.join(item_path, \"ingredients.txt\")\n",
    "           x = PIL.Image.open(img_path)\n",
    "          # print(uuid)\n",
    "           if self.transform:\n",
    "               torch_x = self.transform(x)\n",
    "           np_y = self.read_ingredients(ingredients_path)\n",
    "           torch_y = torch.from_numpy(np_y).float()\n",
    "           return uuid, torch_x, torch_y\n",
    "    data_dir = 'data'\n",
    "    image_datasets = FoodDataset(root=data_dir,\n",
    "        extension='.jpg',\n",
    "        shuffle_frames=True,\n",
    "        subset_size=140000,transform=data_transforms['train']\n",
    "              ,phase=True)\n",
    "\n",
    "    image_datasets_val = FoodDataset(root=data_dir,\n",
    "        extension='.jpg',\n",
    "        shuffle_frames=True,\n",
    "        subset_size=140000,transform=data_transforms['val']\n",
    "              ,phase=False)\n",
    "    print(image_datasets)\n",
    "    print(image_datasets_val)\n",
    "    dataloaders = torch.utils.data.DataLoader(image_datasets, batch_size=4,\n",
    "                                                shuffle=True)\n",
    "\n",
    "    dataloaders_val = torch.utils.data.DataLoader(image_datasets_val, batch_size=4,\n",
    "                                                shuffle=True)\n",
    "                \n",
    "    dataset_sizes = { len(image_datasets) }\n",
    "    class_names = ['pizza','pasta']\n",
    "\n",
    "    device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def imshow(inp, title=None):\n",
    "        \"\"\"Imshow for Tensor.\"\"\"\n",
    "        inp = inp.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        inp = std * inp + mean\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "        plt.imshow(inp)\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        plt.pause(1)  # pause a bit so that plots are updated\n",
    "    #iter(torch.utils.data.DataLoader(dataloaders)).next()\n",
    "\n",
    "    for i_batch, (real_idx, images,labely) in enumerate(dataloaders):\n",
    "        #print(i_batch, real_idx, images,labely)\n",
    "        print(images.size())\n",
    "        print(labely.size())\n",
    "        print(real_idx[0])\n",
    "        break\n",
    "        # observe 4th batch and stop.\n",
    "        if i_batch == 3:\n",
    "            plt.figure()\n",
    "            show_landmarks_batch(sample_batched)\n",
    "            plt.axis('off')\n",
    "            plt.ioff()\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "        \n",
    "        for (batch_num,inputs) in enumerate(dataloaders):\n",
    "            print('batch_num'+str(batch_num))\n",
    "            print('input'+str(inputs))\n",
    "        # Make a grid from batch\n",
    "    labely, inputs, classes = next(iter(dataloaders))\n",
    "\n",
    "# Make a grid from batch\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    " #   imshow(out)\n",
    "\n",
    "\n",
    "    # Get a batch of training data\n",
    "#    inputs, classes = enumerate(dataloaders)\n",
    "    def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "        since = time.time()\n",
    "\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                if phase== 'val':\n",
    "                    for i, (uuid,inputs, labels) in enumerate(dataloaders):\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        # track history if only in train\n",
    "                        with torch.set_grad_enabled(phase == 'train'):\n",
    "                            outputs = model(inputs)\n",
    "                            _, preds = torch.max(outputs, 1)\n",
    "                            loss = criterion(torch.sigmoid(outputs), labels)\n",
    "                            if (i % 100 == 0):\n",
    "                                print('loss', loss)\n",
    "                                torch.save({\n",
    "                                'epoch': epoch,\n",
    "                                'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'loss': loss,\n",
    "                                }, 'models/'+str(epoch)+'.pt')\n",
    "                            # backward + optimize only if in training phase\n",
    "                            if phase == 'train':\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "\n",
    "                        # statistics\n",
    "                       # running_loss += loss.item() * inputs.size(0)\n",
    "                       # running_corrects += torch.sum(preds == labels.data)\n",
    "                elif phase== 'train':\n",
    "                    for i, (uuid,inputs, labels) in enumerate(dataloaders):\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        # track history if only in train\n",
    "                        with torch.set_grad_enabled(phase == 'train'):\n",
    "                            outputs = model(inputs)\n",
    "                            _, preds = torch.max(outputs, 1)\n",
    "                           # print(outputs.dtype)\n",
    "                           # print(labels.dtype)\n",
    "                            loss = criterion(torch.sigmoid(outputs), labels)\n",
    "                            \n",
    "                            if (i % 100 == 0):\n",
    "                                print('loss', loss)\n",
    "                                torch.save({\n",
    "                                'epoch': epoch,\n",
    "                                'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'loss': loss,\n",
    "                                }, 'models/'+str(epoch)+'.pt')\n",
    "                            # backward + optimize only if in training phase\n",
    "                            if phase == 'train':\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "\n",
    "                        # statistics\n",
    "                        #running_loss += loss.item() * inputs.size(0)\n",
    "                        #running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                #epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                #print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                 #   phase, epoch_loss, epoch_acc))\n",
    "\n",
    "                # deep copy the model\n",
    "                #if phase == 'val' and epoch_acc > best_acc:\n",
    "                #    best_acc = epoch_acc\n",
    "                #    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            #print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        return model\n",
    "    def visualize_model(model, datasetname, num_images=6):\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "        images_so_far = 0\n",
    "        print(plt.rcParams['font.family']) #現在使用しているフォントを表示\n",
    "        plt.rcParams['font.family'] = ['sans-serif']\n",
    "        plt.rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
    "        print(plt.rcParams['font.family']) #現在使用しているフォントを表示\n",
    "        fig = plt.figure()\n",
    "        with torch.no_grad():\n",
    "            for i, (uuid,inputs, labels) in enumerate(dataloaders_val):\n",
    "                print(uuid)\n",
    "                print(i)\n",
    "                fm.findSystemFonts()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                outputs= outputs.to(device)\n",
    "              #  print(outputs)\n",
    "                #print(labels.tolist())\n",
    "\n",
    "\n",
    "                for j in range(inputs.size()[0]):\n",
    "                    ing_list=[]\n",
    "                    for i in range(len(outputs.tolist()[j])):\n",
    "                        if(outputs[j][i])>-2:\n",
    "                            ing_list.append(datasetname.num_to_label[i])\n",
    "\n",
    "                    print(ing_list)\n",
    "                    images_so_far += 1\n",
    "                    ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                    ax.axis('off')\n",
    "                    ax.set_title(u'predicted: {}'.format(ing_list), fontname=\"sans-serif\")\n",
    "                    imshow(inputs.cpu().data[j])\n",
    "                    if images_so_far == num_images:\n",
    "                        time.sleep(1000)\n",
    "                        model.train(mode=was_training)\n",
    "\n",
    "            model.train(mode=was_training)\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    # Here the size of each output sample is set to 2.\n",
    "    # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "    model_ft.fc = nn.Linear(num_ftrs,329)\n",
    "    # Observe that all parameters are being optimized\n",
    "    \"\"\" \n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "\n",
    "    model_ft = model_ft.to(device) \"\"\"\n",
    "    model_ft = model_ft.to(device)\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "   # try:\n",
    "    checkpoint = torch.load('models/24.pt' ,map_location=torch.device('cpu'))\n",
    "    model_ft.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer_ft.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print('epoch :{} loss: {}'.format(epoch,loss))\n",
    "#except:\n",
    "       # print('no files')\n",
    "\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.BCELoss()\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "    #model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)\n",
    "    visualize_model(model_ft,image_datasets_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
